{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T06:58:56.095971Z",
     "iopub.status.busy": "2024-12-16T06:58:56.095739Z",
     "iopub.status.idle": "2024-12-16T06:58:56.103353Z",
     "shell.execute_reply": "2024-12-16T06:58:56.102515Z",
     "shell.execute_reply.started": "2024-12-16T06:58:56.095950Z"
    },
    "id": "5rCxttmfrlqU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "epochs = 5\n",
    "\n",
    "is_colab = False\n",
    "img_with = 256\n",
    "img_size = [img_with, img_with]\n",
    "img_dims = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8wTxDLB2CSt"
   },
   "source": [
    "# Setup tensorflow and devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-12-16T06:58:56.122985Z",
     "iopub.status.busy": "2024-12-16T06:58:56.122749Z",
     "iopub.status.idle": "2024-12-16T06:59:04.297093Z",
     "shell.execute_reply": "2024-12-16T06:59:04.296226Z",
     "shell.execute_reply.started": "2024-12-16T06:58:56.122959Z"
    },
    "id": "1pA-Vy932CSv",
    "outputId": "5df92e13-6cb7-45cd-9c9b-ac7a05353ddb",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaggle_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KaggleDatasets\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# If we have a TPU available, we'll use it\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tensorflow.python.profiler import profiler_client\n",
    "\n",
    "# Kaggle doesn't have drive and colab doesn't have kaggle_datasets\n",
    "if is_colab:\n",
    "    from google.colab import drive\n",
    "else:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    import tensorflow_addons as tfa\n",
    "\n",
    "# If we have a TPU available, we'll use it\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Replicas available:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88wbJBEE2CS9"
   },
   "source": [
    "# Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-16T06:59:04.300008Z",
     "iopub.status.busy": "2024-12-16T06:59:04.299019Z",
     "iopub.status.idle": "2024-12-16T06:59:05.114559Z",
     "shell.execute_reply": "2024-12-16T06:59:05.112184Z",
     "shell.execute_reply.started": "2024-12-16T06:59:04.299973Z"
    },
    "id": "PPSeqVxF2CS9",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2ed0cebe-af7f-40fd-cb9b-94869bf2afc3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if is_colab:\n",
    "    drive.mount('/content/drive')\n",
    "    path = '/content/drive/MyDrive/Colab Notebooks/Datasets/monet'\n",
    "    models_path = f'/content/drive/MyDrive/Colab Notebooks/Big Data Intelligence/Final Project/models/models_epoch_{epochs}'\n",
    "else:\n",
    "    path = KaggleDatasets().get_gcs_path('monet-gan-getting-started')\n",
    "    models_path  = \"/kaggle/input/monet-cyclegan-models/models_epoch_75_augmented-20241216T104407Z-001/models_epoch_75_augmented\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.115572Z",
     "iopub.status.idle": "2024-12-16T06:59:05.115893Z",
     "shell.execute_reply": "2024-12-16T06:59:05.115756Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.115741Z"
    },
    "id": "96z6UD-52CS-",
    "outputId": "167d33df-1dd0-41cc-9c58-e375f7341760",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "paintings = tf.io.gfile.glob(f'{path}/monet_tfrec/*.tfrec')\n",
    "print(f'The dataset contains: {len(paintings)} monet paintings')\n",
    "\n",
    "photos = tf.io.gfile.glob(f'{path}/photo_tfrec/*.tfrec')\n",
    "print(f'The dataset contains: {len(photos)} real photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.116894Z",
     "iopub.status.idle": "2024-12-16T06:59:05.117155Z",
     "shell.execute_reply": "2024-12-16T06:59:05.117039Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.117027Z"
    },
    "id": "MEmNIlbM2CS-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Turn the dataset into a list for easy access\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=img_dims)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*img_size, img_dims])\n",
    "    return image\n",
    "\n",
    "# Read the TFRecord file\n",
    "def read_tfrecord(list):\n",
    "    tfrecord_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    list = tf.io.parse_single_example(list, tfrecord_format)\n",
    "    image = decode_image(list['image'])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.117878Z",
     "iopub.status.idle": "2024-12-16T06:59:05.118161Z",
     "shell.execute_reply": "2024-12-16T06:59:05.118039Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.118025Z"
    },
    "id": "6GWiRgJb2CS_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD9s6kWy2CS_"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.119291Z",
     "iopub.status.idle": "2024-12-16T06:59:05.119624Z",
     "shell.execute_reply": "2024-12-16T06:59:05.119461Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.119447Z"
    },
    "id": "t4Xvf4B72CTA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "monet_ds = load_dataset(paintings, labeled=True).batch(1)\n",
    "photo_ds = load_dataset(photos, labeled=True).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daniels insane image atmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.120696Z",
     "iopub.status.idle": "2024-12-16T06:59:05.121096Z",
     "shell.execute_reply": "2024-12-16T06:59:05.120910Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.120891Z"
    },
    "id": "dmW1lHSX2CTB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation function (only spatial transformations)\n",
    "# Function to augment a single image (non-color-changing augmentations)\n",
    "def augment_image(image):\n",
    "    # Random flip left-right\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # Random flip up-down\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    # Random rotation (90-degree steps)\n",
    "    image = tf.image.rot90(image, k=np.random.randint(1, 4))  # Random 90, 180, 270 degrees\n",
    "    # Return augmented image\n",
    "    return image\n",
    "\n",
    "# Function to generate augmented versions of the dataset\n",
    "def augment_dataset(dataset, num_augmented_copies):\n",
    "    augmented_dataset = dataset\n",
    "    for _ in range(num_augmented_copies):\n",
    "        augmented_images = dataset.map(\n",
    "            lambda x: augment_image(x), num_parallel_calls=AUTOTUNE\n",
    "        )\n",
    "        augmented_dataset = augmented_dataset.concatenate(augmented_images)\n",
    "    return augmented_dataset\n",
    "\n",
    "# Increase the dataset size by creating 2 augmented copies of each image\n",
    "num_augmented_copies = 2\n",
    "augmented_monet_ds = augment_dataset(monet_ds, num_augmented_copies)\n",
    "# augmented_photo_ds = augment_dataset(photo_ds, num_augmented_copies)\n",
    "print(augmented_monet_ds.element_spec)\n",
    "# Shuffle and batch the datasets\n",
    "augmented_monet_ds = augmented_monet_ds.shuffle(1024).prefetch(AUTOTUNE)\n",
    "\n",
    "# augmented_monet_ds = augmented_monet_ds.shuffle(1024).batch(1).prefetch(AUTOTUNE)\n",
    "print(augmented_monet_ds.element_spec)\n",
    "# augmented_photo_ds = augmented_photo_ds.shuffle(1024).batch(1).prefetch(AUTOTUNE)\n",
    "\n",
    "# Check the size of the augmented dataset\n",
    "print(\"Original Monet dataset size:\", len(list(monet_ds)))\n",
    "print(\"Augmented Monet dataset size:\", len(list(augmented_monet_ds)))\n",
    "# print(\"Original Photo dataset size:\", len(list(photo_ds)))\n",
    "# print(\"Augmented Photo dataset size:\", len(list(augmented_photo_ds)))\n",
    "\n",
    "print(monet_ds.element_spec)\n",
    "monet_ds = augmented_monet_ds\n",
    "print(monet_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.122374Z",
     "iopub.status.idle": "2024-12-16T06:59:05.122808Z",
     "shell.execute_reply": "2024-12-16T06:59:05.122611Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.122592Z"
    },
    "id": "qn0F1wud2CTC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "example_monet = next(iter(monet_ds))\n",
    "example_photo = next(iter(photo_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.124137Z",
     "iopub.status.idle": "2024-12-16T06:59:05.124420Z",
     "shell.execute_reply": "2024-12-16T06:59:05.124295Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.124282Z"
    },
    "id": "qwqJn_Mt2CTC",
    "outputId": "76f0b8a7-877b-492d-9e9f-3bb18da28372",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Photo')\n",
    "plt.axis('off')\n",
    "plt.imshow(example_photo[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Monet')\n",
    "plt.axis('off')\n",
    "plt.imshow(example_monet[0] * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dM16sQeJdY-"
   },
   "source": [
    "# Chriss Custom Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.125323Z",
     "iopub.status.idle": "2024-12-16T06:59:05.125619Z",
     "shell.execute_reply": "2024-12-16T06:59:05.125468Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.125456Z"
    },
    "id": "XXYzE6H8Jfan",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InstanceNormalization(layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='ones',\n",
    "            trainable=True,\n",
    "            name=\"gamma\"\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name=\"beta\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean, variance = tf.nn.moments(inputs, axes=[1, 2], keepdims=True)\n",
    "        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
    "        return self.gamma * normalized + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dhzJq6i2CTC"
   },
   "source": [
    "# Build the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.129226Z",
     "iopub.status.idle": "2024-12-16T06:59:05.129540Z",
     "shell.execute_reply": "2024-12-16T06:59:05.129393Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.129375Z"
    },
    "id": "bFdGsEGd2CTD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False, apply_instancenorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = keras.Sequential()\n",
    "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "    if apply_instancenorm:\n",
    "        result.add(InstanceNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(layers.Dropout(0.5))\n",
    "\n",
    "    result.add(layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.130487Z",
     "iopub.status.idle": "2024-12-16T06:59:05.130772Z",
     "shell.execute_reply": "2024-12-16T06:59:05.130657Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.130645Z"
    },
    "id": "sjdbo8gU2CTD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def Generator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inputs = layers.Input(shape=[img_with, img_with, img_dims])\n",
    "\n",
    "    # ---------- Encoder (Downsampling) ---------- \n",
    "    skips = []\n",
    "\n",
    "    # Downsample 1: (bs, 256, 256, 3) -> (bs, 128, 128, 64)\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(inputs)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    skips.append(x)\n",
    "\n",
    "    # Downsample 2: (bs, 128, 128, 64) -> (bs, 64, 64, 128)\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    skips.append(x)\n",
    "\n",
    "    # Downsample 3: (bs, 64, 64, 128) -> (bs, 32, 32, 256)\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    skips.append(x)\n",
    "\n",
    "    # Downsample 4-7: (bs, 32, 32, 256) -> (bs, 16, 16, 512) -> (bs, 8, 8, 512) -> (bs, 4, 4, 512) -> (bs, 2, 2, 512)\n",
    "    for _ in range(4):\n",
    "        x = layers.Conv2D(512, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "        skips.append(x)\n",
    "\n",
    "# ---------- Decoder (Upsampling) ---------- \n",
    "    # Reverse skips for skip connections\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsample: (bs, 2, 2, 512) -> (bs, 4, 4, 1024) -> concatenate -> (bs, 4, 4, 1024)\n",
    "    for filters, apply_dropout in zip([512, 512, 512, 512, 256, 128, 64], [True, True, True, False, False, False, False]):\n",
    "        x = layers.Conv2DTranspose(filters, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        if apply_dropout:\n",
    "            x = layers.Dropout(0.5)(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        skip = next(skips)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "\n",
    "    # Final layer: (bs, 128, 128, 64) -> (bs, 256, 256, 3)\n",
    "    x = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh')(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-5ekxZm2CTD"
   },
   "source": [
    "# Build the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.131863Z",
     "iopub.status.idle": "2024-12-16T06:59:05.132258Z",
     "shell.execute_reply": "2024-12-16T06:59:05.132073Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.132054Z"
    },
    "id": "dMqPRLfy2CTE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "\n",
    "    # Downsample 1: (bs, 256, 256, 3) -> (bs, 128, 128, 64)\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(inp)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    # Downsample 2: (bs, 128, 128, 64) -> (bs, 64, 64, 128)\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    # Downsample 3: (bs, 64, 64, 128) -> (bs, 32, 32, 256)\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    # Downsample 4: (bs, 32, 32, 256) -> (bs, 31, 31, 512)\n",
    "    x = layers.ZeroPadding2D()(x)  # (bs, 34, 34, 256)\n",
    "    x = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    # Final layer: (bs, 31, 31, 512) -> (bs, 30, 30, 1)\n",
    "    x = layers.ZeroPadding2D()(x)  # (bs, 33, 33, 512)\n",
    "    x = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.133322Z",
     "iopub.status.idle": "2024-12-16T06:59:05.133790Z",
     "shell.execute_reply": "2024-12-16T06:59:05.133549Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.133529Z"
    },
    "id": "I5-zGXJn2CTE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    monet_generator = Generator() # transforms photos to Monet-esque paintings\n",
    "    monet_discriminator = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n",
    "\n",
    "    photo_generator = Generator() # transforms Monet paintings to be more like photos\n",
    "    photo_discriminator = Discriminator() # differentiates real photos and generated photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.134803Z",
     "iopub.status.idle": "2024-12-16T06:59:05.135193Z",
     "shell.execute_reply": "2024-12-16T06:59:05.135010Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.134992Z"
    },
    "id": "MMoVcjgH2CTE",
    "outputId": "ee4f0cc6-99b9-4b21-b1a5-10a072028934",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "to_monet = monet_generator(example_photo)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Photo\")\n",
    "plt.imshow(example_photo[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Monet-esque Photo\")\n",
    "plt.imshow(to_monet[0] * 0.5 + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsLCyk6M2CTE"
   },
   "source": [
    "# Build the CycleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.136956Z",
     "iopub.status.idle": "2024-12-16T06:59:05.137358Z",
     "shell.execute_reply": "2024-12-16T06:59:05.137171Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.137152Z"
    },
    "id": "4NlIcgcR2CTE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monet_generator,\n",
    "        photo_generator,\n",
    "        monet_discriminator,\n",
    "        photo_discriminator,\n",
    "        lambda_cycle=10,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        m_gen_optimizer,\n",
    "        p_gen_optimizer,\n",
    "        m_disc_optimizer,\n",
    "        p_disc_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        real_monet, real_photo = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # photo to monet back to photo\n",
    "            fake_monet = self.m_gen(real_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "\n",
    "            # monet to photo back to monet\n",
    "            fake_photo = self.p_gen(real_monet, training=True)\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "\n",
    "            # generating itself\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing real images\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing fake images\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "\n",
    "            # evaluates generator loss\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            # evaluates total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates total generator loss\n",
    "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
    "                                                  self.m_gen.trainable_variables)\n",
    "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
    "                                                  self.p_gen.trainable_variables)\n",
    "\n",
    "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
    "                                                      self.m_disc.trainable_variables)\n",
    "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
    "                                                      self.p_disc.trainable_variables)\n",
    "\n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
    "                                                 self.m_gen.trainable_variables))\n",
    "\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
    "                                                 self.p_gen.trainable_variables))\n",
    "\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
    "                                                  self.m_disc.trainable_variables))\n",
    "\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
    "                                                  self.p_disc.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23_US_Pd2CTF"
   },
   "source": [
    "# Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.139077Z",
     "iopub.status.idle": "2024-12-16T06:59:05.139488Z",
     "shell.execute_reply": "2024-12-16T06:59:05.139297Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.139278Z"
    },
    "id": "GCCBZoOs2CTF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def discriminator_loss(real, generated):\n",
    "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
    "\n",
    "        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
    "\n",
    "        total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "        return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.140451Z",
     "iopub.status.idle": "2024-12-16T06:59:05.140879Z",
     "shell.execute_reply": "2024-12-16T06:59:05.140691Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.140670Z"
    },
    "id": "TQ85YBJ92CTF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def generator_loss(generated):\n",
    "        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.142082Z",
     "iopub.status.idle": "2024-12-16T06:59:05.142497Z",
     "shell.execute_reply": "2024-12-16T06:59:05.142292Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.142273Z"
    },
    "id": "nLl3vltE2CTF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
    "        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "        return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.144368Z",
     "iopub.status.idle": "2024-12-16T06:59:05.144790Z",
     "shell.execute_reply": "2024-12-16T06:59:05.144592Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.144573Z"
    },
    "id": "UJIL87eX2CTF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def identity_loss(real_image, same_image, LAMBDA):\n",
    "        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "        return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoGgX71M2CTF"
   },
   "source": [
    "# Train the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.145786Z",
     "iopub.status.idle": "2024-12-16T06:59:05.146185Z",
     "shell.execute_reply": "2024-12-16T06:59:05.146001Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.145981Z"
    },
    "id": "ans9qVrF2CTF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.147710Z",
     "iopub.status.idle": "2024-12-16T06:59:05.148119Z",
     "shell.execute_reply": "2024-12-16T06:59:05.147920Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.147901Z"
    },
    "id": "sNMIl0hy2CTG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer = monet_generator_optimizer,\n",
    "        p_gen_optimizer = photo_generator_optimizer,\n",
    "        m_disc_optimizer = monet_discriminator_optimizer,\n",
    "        p_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.149354Z",
     "iopub.status.idle": "2024-12-16T06:59:05.149662Z",
     "shell.execute_reply": "2024-12-16T06:59:05.149528Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.149494Z"
    },
    "id": "Xz4PtGZV2CTG",
    "outputId": "e0177e27-4073-480a-afe8-2e04072ddf18",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If we are on kaggle we skip this step and import instead\n",
    "if is_colab:\n",
    "    cycle_gan_model.fit(\n",
    "        tf.data.Dataset.zip((monet_ds, photo_ds)),\n",
    "        epochs=epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOUqEIrP9awC"
   },
   "source": [
    "# Save/Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.150696Z",
     "iopub.status.idle": "2024-12-16T06:59:05.150949Z",
     "shell.execute_reply": "2024-12-16T06:59:05.150836Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.150824Z"
    },
    "id": "1sG5TlDt9awC",
    "outputId": "020f0a66-a52b-40d5-91d8-8c9d0a47bc81",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# We save our Model so we can add it to Kaggle\n",
    "if is_colab:\n",
    "    monet_generator.save(f'{models_path}/monet_generator', save_format='h5')\n",
    "    photo_generator.save(f'{models_path}/photo_generator', save_format='h5')\n",
    "    monet_discriminator.save(f'{models_path}/monet_discriminator', save_format='h5')\n",
    "    photo_discriminator.save(f'{models_path}/photo_discriminator', save_format='h5')\n",
    "# If we are on Kaggle, import our models\n",
    "else: \n",
    "    monet_generator.load_weights(f'{models_path}/monet_generator')\n",
    "    photo_generator.load_weights(f'{models_path}/photo_generator')\n",
    "    monet_discriminator.load_weights(f'{models_path}/monet_discriminator')\n",
    "    photo_discriminator.load_weights(f'{models_path}/photo_discriminator')\n",
    "    print(\"Models imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_68i-y62CTG"
   },
   "source": [
    "# Visualize our Monet-esque photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.151922Z",
     "iopub.status.idle": "2024-12-16T06:59:05.152185Z",
     "shell.execute_reply": "2024-12-16T06:59:05.152068Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.152056Z"
    },
    "id": "JiMCxDbx2CTH",
    "outputId": "f84fb06b-4394-4dc1-e1bf-1e5b1b10d0b6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "_, ax = plt.subplots(2, 5, figsize=(15, 6))\n",
    "random_photos = list(photo_ds.shuffle(buffer_size=100).take(5))  # Randomly shuffle and select 5 images\n",
    "\n",
    "for i, img in enumerate(random_photos):\n",
    "    prediction = monet_generator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "    ax[0, i].imshow(img)  # Input photo in the first row\n",
    "    ax[1, i].imshow(prediction)  # Monet-esque in the second row\n",
    "    ax[0, i].set_title(\"Input Photo\")\n",
    "    ax[1, i].set_title(\"Monet-esque\")\n",
    "    ax[0, i].axis(\"off\")\n",
    "    ax[1, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62srnKXW2CTH"
   },
   "source": [
    "# Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.153546Z",
     "iopub.status.idle": "2024-12-16T06:59:05.153835Z",
     "shell.execute_reply": "2024-12-16T06:59:05.153716Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.153703Z"
    },
    "id": "cEDDjZr_2CTH",
    "outputId": "d9c48e5b-a43e-4645-8066-8b26e96e4529",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "! mkdir ../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.155184Z",
     "iopub.status.idle": "2024-12-16T06:59:05.155445Z",
     "shell.execute_reply": "2024-12-16T06:59:05.155326Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.155315Z"
    },
    "id": "ztIPrxz32CTH",
    "outputId": "8aec5306-3c8b-4652-8333-51219f6a54af",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for img in photo_ds:\n",
    "    prediction = monet_generator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    im = PIL.Image.fromarray(prediction)\n",
    "    im.save(\"../images/\" + str(i) + \".jpg\")\n",
    "    i += 1\n",
    "    if i % 200 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-16T06:59:05.156272Z",
     "iopub.status.idle": "2024-12-16T06:59:05.156580Z",
     "shell.execute_reply": "2024-12-16T06:59:05.156433Z",
     "shell.execute_reply.started": "2024-12-16T06:59:05.156419Z"
    },
    "id": "RYVq9Jl_2CTH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    },
    {
     "datasetId": 6309834,
     "sourceId": 10215461,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30299,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
